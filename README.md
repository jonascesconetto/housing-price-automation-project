## Automa√ß√£o de Projetos de Data Science utilizando Apache Airflow
  Este reposit√≥rio cont√©m alguns arquivos e c√≥digos utilizados durante curso de `Data Pipelines com Apache Airflow `.
### Objetivo do projeto
  - Predi√ß√£o do log do erro entre a estimativa da Zillow e o pre√ßo atual dos im√≥veis.
  - [Link](https://www.kaggle.com/competitions/zillow-prize-1/data) da competi√ß√£o Zillow

Projeto consiste em desenvolver todo o processo de automatiza√ß√£o para um projeto de `Data Science`, no qual possui as seguintes etapas:
  1. Carga de dados
  2. Limpeza
  3. An√°lise e explora√ß√†o
  4. Pr√©-processamento e transforma√ß√†o
  5. Feature Engineering
  6. Ajustes e Avalia√ß√£o
  7. Deploy
## üíª Principais Tecnologias, Softwares e Bibliotecas
- Python
- Projeto Anaconda
- Docker 
- Apache AirFlow (Data Pipeline)
## ‚öô Instala√ß√£o e configura√ß√£o de ambiente (local)
### Projeto Anaconda
 - Seguir a [documenta√ß√£o](https://www.anaconda.com/) oficial.
## ‚öô Instala√ß√£o e configura√ß√£o de ambiente (Docker)
### Docker
  - Seguir a [documenta√ß√£o](https://docs.docker.com/engine/install/) oficial.
### Container - Apache AirFlow
  - `Observa√ß√£o: `Abra o terminal em um diret√≥rio raiz para subir seu container com Airflow, dessa forma n√£o perdemos os arquivos de DAGs gerados caso seja necess√°rio algumas reinstala√ß√£o ou configura√ß√£o adicional do container.
  - Crie container com seguinte comando em seu terminal:
    ```bash
    docker run -d -p 8080:8080 -v "$PWD/airflow/dags:/opt/airflow/dags/" \
    --entrypoint=/bin/bash \
    --name airflow apache/airflow:2.3.4-python3.8 \
    -c '(\
    airflow db init && \
    airflow users create --username <nome de usu√°rio> --password <sua senha> --firstname <Seu nome> --lastname <Seu Nome> --role Admin --email <Seu e-mail>); \
    airflow webserver & \
    airflow scheduler\
    '
    ```
  - Verificando o container em execu√ß√£o.
    ```bash
    docker container ls
    ```
  - Verificando os logs do container
    ```bash
    docker container logs airflow
    ```
  - Se nenhum erro aparecer, acesse a interface web do Apache Airflow pelo endere√ßo:
    
    **https://localhost:8080**
### Instalando bibliotecas necess√°rias
  - Acessar o container do Airflow como root
    ```bash
    docker container exec -it --user root airflow bash
    ```
  - Seaborn joblib
    ```bash
    pip install joblib
    ```
  - Sklearn
    ```bash
    sudo pip install sklearn
    ```
## Executando 
### Testar o `notebook`do projeto
  - Dentro do diret√≥rio `notebooks` executar cada um dos arquivos listados.
### Testar a `DAG` do projeto
- `pipeline_data_science_housing_price`  
## Vantagens e Desvantagens 
### Vantagens
- Integra√ß√£o com outros componentes
- Toler√¢ncia a falhas
- Alertas personalizados
- Opera√ß√µes independentes
  - Redu√ß√£o do tempo de processamento e custos
- Melhor versionamento e log
- F√°cil manuten√ß√†o e controle de erros
- Melhor controle de fluxos
- F√°cil integra√ß√£o entre equipes de Engenharia e Ci√™ncia de Dados
### Desvantagens
- Maior curva de aprendizado
- Maior tempo de desenvolvimento